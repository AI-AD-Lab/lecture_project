import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.nn import functional as F
import os
import numpy as np

# --- 1. ëª¨ë¸ ë° ë°ì´í„°ì…‹ ì •ì˜ íŒŒì¼ ìž„í¬íŠ¸ (ê°€ì •) ---
# ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë§žê²Œ ìˆ˜ì • í•„ìš”
from seg_decoder import SegHead
from efficient_sam.efficient_sam_encoder import ImageEncoderViT 
from datasets.RELLIS_3D_dataset import RELLIS3DDataset 
# from your_project.utils import DiceLoss, iou_metric 

# *ì£¼ì˜: ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ê²½ë¡œë¥¼ ë§žì¶”ì„¸ìš”.*

# ìž„ì‹œ ì •ì˜ (ì‹¤ì œ ì½”ë“œë¡œ ëŒ€ì²´ í•„ìš”)
class SegHead(nn.Module):
    def __init__(self):
        super().__init__()
        # SAMAggregatorNeckê³¼ SegHeadë¥¼ í†µí•©í•œ ê°„ì†Œí™”ëœ êµ¬ì¡°
        self.conv = nn.Conv2d(1280, 2, kernel_size=1) 
    def forward(self, inputs):
        # ImageEncoderViTì˜ íŠœí”Œ ì¶œë ¥ì„ ë°›ìŒ: (final_embedding, inner_states)
        final_embedding, inner_states = inputs
        # SegHeadì˜ ìµœì¢… ì¶œë ¥ì„ 256x256 ë¡œì§“ìœ¼ë¡œ ê°€ì •
        return F.interpolate(self.conv(final_embedding), size=(256, 256), mode='bilinear', align_corners=False)

class ImageEncoderViT(nn.Module):
    def __init__(self):
        super().__init__()
        # SAM ì¸ì½”ë” ì—­í•  (ê°€ì¤‘ì¹˜ëŠ” ë¡œë“œë˜ì—ˆë‹¤ê³  ê°€ì •)
        self.dummy_output = nn.Parameter(torch.randn(1, 1280, 64, 64)) 
        self.dummy_states = [torch.randn(1, 64, 64, 384)] * 12
    def forward(self, x):
        # ì‹¤ì œ ì¸ì½”ë”ëŠ” ë¡œë“œëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ë©°, íŠœí”Œì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ì„¤ëª…ì„ ìœ„í•´ ë”ë¯¸(Dummy) ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        return self.dummy_output.repeat(x.size(0), 1, 1, 1), self.dummy_states 

# ************************************************

# --- 2. ì†ì‹¤ í•¨ìˆ˜ ë° í‰ê°€ ì§€í‘œ (ì˜ˆì‹œ) ---
class CombinedLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.ce_loss = nn.CrossEntropyLoss()
        # ì¼ë°˜ì ìœ¼ë¡œ Dice Lossê°€ ê²½ê³„ í•™ìŠµì— ìœ ë¦¬í•©ë‹ˆë‹¤.
        # self.dice_loss = DiceLoss() 

    def forward(self, pred, target):
        ce = self.ce_loss(pred, target)
        # dice = self.dice_loss(F.softmax(pred, dim=1)[:, 1], target.float())
        return ce # + dice

# --- 3. í›ˆë ¨ ë° ê²€ì¦ í•¨ìˆ˜ ---

def train_one_epoch(model, dataloader, criterion, optimizer, device):
    model.train()
    total_loss = 0
    for data in dataloader:
        images = data['rgb_image'].to(device)
        # ë ˆì´ë¸”ì€ Long íƒ€ìž…ì´ì–´ì•¼ nn.CrossEntropyLossì— ì í•©í•©ë‹ˆë‹¤.
        labels = data['label'].long().to(device) 

        # ì¸ì½”ë”ë¥¼ no_gradë¡œ ê°ì‹¸ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ë°©ì§€ (ê°€ìž¥ ì¤‘ìš”)
        with torch.no_grad():
            image_embedding, inner_states = model['encoder'](images)
            
        inputs_for_decoder = (image_embedding, inner_states)
        pred_logits = model['decoder'](inputs_for_decoder)
        
        loss = criterion(pred_logits, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    return total_loss / len(dataloader)


def validate_model(model, dataloader, device):
    model['decoder'].eval()
    total_iou = 0
    with torch.no_grad():
        for data in dataloader:
            images = data['rgb_image'].to(device)
            labels = data['label'].long().to(device)

            image_embedding, inner_states = model['encoder'](images)
            inputs_for_decoder = (image_embedding, inner_states)
            pred_logits = model['decoder'](inputs_for_decoder)
            
            # ì˜ˆì¸¡ ë§ˆìŠ¤í¬ (Freepace í´ëž˜ìŠ¤)
            predicted_mask = torch.argmax(pred_logits, dim=1) 
            
            # IoU ê³„ì‚° (ì‹¤ì œ iou_metric í•¨ìˆ˜ë¡œ ëŒ€ì²´ í•„ìš”)
            # iou = iou_metric(predicted_mask, labels) 
            total_iou += 1 # ìž„ì‹œ ê°’
    return total_iou / len(dataloader)


# --- 4. ë©”ì¸ ì‹¤í–‰ ë£¨í”„ (best_epoch.pth ìƒì„± ë¡œì§ í¬í•¨) ---

def main_train_script():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 4.1 ëª¨ë¸ ë¡œë“œ ë° ë™ê²° ì„¤ì •
    image_encoder = ImageEncoderViT().to(device)
    # image_encoder.load_state_dict(torch.load('weights/sam_vit_h_4b8939.pth')['model'], strict=False)
    
    # ì¸ì½”ë” íŒŒë¼ë¯¸í„° ë™ê²° (í•„ìˆ˜!)
    for param in image_encoder.parameters():
        param.requires_grad = False
    
    seg_decoder = SegHead().to(device) # ë””ì½”ë”ëŠ” ëžœë¤ ì´ˆê¸°í™” ìƒíƒœ
    
    model = {'encoder': image_encoder, 'decoder': seg_decoder}

    # 4.2 ë°ì´í„° ë¡œë” (RELLIS3DDataset ë° DataLoader ì‚¬ìš©)
    # train_dataset = RELLIS3DDataset(root='your_path', mode='train')
    # val_dataset = RELLIS3DDataset(root='your_path', mode='val')
    # train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
    # val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)
    
    # *ì£¼ì˜: ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ìœ„ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  DataLoaderë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.*
    
    # 4.3 ìµœì í™” ì„¤ì •
    criterion = CombinedLoss()
    # ì˜µí‹°ë§ˆì´ì €ëŠ” ë””ì½”ë” íŒŒë¼ë¯¸í„°ë§Œ í•™ìŠµí•˜ë„ë¡ ì§€ì • (í•„ìˆ˜!)
    optimizer = optim.AdamW(seg_decoder.parameters(), lr=1e-4) 

    # 4.4 í›ˆë ¨ ë£¨í”„ ë° ì €ìž¥
    num_epochs = 50
    best_iou = -1.0
    ckpt_dir = 'ckpts/orfd'
    os.makedirs(ckpt_dir, exist_ok=True)
    
    for epoch in range(num_epochs):
        # train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)
        # val_iou = validate_model(model, val_loader, device)

        # *ì£¼ì˜: ì‹¤ì œ IoUì™€ Loss ë¡œê·¸ ì¶œë ¥ ì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.*

        # ðŸ’¥ best_epoch.pth íŒŒì¼ ìƒì„± ë¡œì§ (ê°€ìž¥ ì¤‘ìš”)
        # if val_iou > best_iou: 
        #     best_iou = val_iou
        #     torch.save(seg_decoder.state_dict(), os.path.join(ckpt_dir, 'best_epoch.pth'))
        #     print(f"Epoch {epoch+1}: New best IoU {best_iou:.4f}. Saved best_epoch.pth")
        
        # ìž„ì‹œ ì¶œë ¥
        print(f"Epoch {epoch+1} completed. best_epoch.pth file is created upon successful validation.")


if __name__ == '__main__':
    main_train_script()